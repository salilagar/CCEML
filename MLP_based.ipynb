{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the required packages in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux;\n",
    "using Flux.Data.MNIST;\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Statistics\n",
    "using Base.Iterators: repeated, partition\n",
    "using Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the images and labels from MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = MNIST.images();\n",
    "labels = MNIST.labels();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rewrite (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rewrite(r)  # rewrite a range r of images\n",
    "\n",
    "    X = hcat([vec(Float64.(images[i])) for i in r]...)\n",
    "    Y = onehotbatch(labels[r], 0:9)\n",
    "    \n",
    "    return (X, Y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for training using first 5000 images of the training dataset (to keep the training time limited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[false true … false false; false false … true false; … ; false false … false false; false false … false false])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5000\n",
    "X, Y = rewrite(1:N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model as dense model with 784 input (the same as number of pixels in each image). The hidden layer of 255 neurons and and output layer of 10 neurons (one for each digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 255, NNlib.relu), Dense(255, 10, NNlib.relu), NNlib.softmax)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = length(vec(images[1]))\n",
    "\n",
    "model = \n",
    "  Chain(\n",
    "      Dense(n, 255, relu), \n",
    "      Dense(255, 10, relu),#   Dense(10, 10),\n",
    "      softmax\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(i) = findmax(model(Float64.(vec(images[i]))))[2] # returns (max_value, index)\n",
    "function accuracy()\n",
    "    which_correct = [prediction(i) == (labels[i]) + 1 for i in N+1:N+1000];\n",
    "    return count(which_correct) / 1000\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is calculated by providing image 5001 - 6000 as input and comparing the predicted value against the actual provided in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.crossentropy(model(x), y)\n",
    "opt = ADAM(params(model))\n",
    "l = loss(X, Y)\n",
    "evalcb = throttle(() -> @show(accuracy()), 10)\n",
    "\n",
    "Flux.Tracker.back!(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}}(Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}(([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[false true … false false; false false … true false; … ; false false … false false; false false … false false])), 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Base.Iterators.repeated((X, Y), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy() = 0.306\n",
      "accuracy() = 0.731\n",
      "accuracy() = 0.763\n",
      "accuracy() = 0.827\n",
      "accuracy() = 0.846\n",
      "accuracy() = 0.852\n",
      "accuracy() = 0.852\n",
      " 80.072117 seconds (11.22 M allocations: 8.922 GiB, 17.09% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(loss, dataset, opt, cb = evalcb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function takes input as RGB image of the number created as explained in the report. It returns the output as the number by inferencing based on the model created above. The number can be any single digit or multiple digit number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_image (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_image(num_img)\n",
    "    num_gs = Gray.(num_img)\n",
    "    imgs = [num_gs[1:28, (i-1)*28 + 1: i*28] for i in 1:(Int64((size(num_gs)[2])/28))]\n",
    "    number = 0\n",
    "    i = 0\n",
    "    for j in reverse(1:length(imgs))\n",
    "        mynum = findmax(model(Float64.(vec(imgs[j]))))[2]  .-1\n",
    "        number = number + (10^i)*mynum\n",
    "        i += 1\n",
    "    end\n",
    "    return number\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all images (only with jpg extension) to my_images array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKgAAABUCAAAAAAzcCMKAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAK9SURBVGje7ZrZkqMwDEWPDMnk/7823Q32PKiliJClQ82EUpfvA0Wx2ELXWrFwHwLNjvHKLig7zft7BZV7NwZoUAEYYd6PdEUajaYRVB7fLsZ4gxOc9xM0jUbTCHqX+j/wAcAAMxSodtwFaTSaRtBHVq8m32CAuor7b0YajaYRVJ4+cYAve27HcJ9Go2kElQc3mn2KO3ldBrsgjUbTCHqX+mYevoLAuF+UV6TRaBpBRYxfh3Kta2Kwsm6GcWus10Gw132EGQa77mHl3vhpNJpG0IvVew4vxlREs+p+M3wVVWO82DKrJken/o0YXVhN46PJ+8kMFeatVl+C39CJymqiBgeYfoFG0wg6Dsap5m8jTHZ0lku49So8mpQwZrXRBssopmeLKo1G0wgqhDg7BHLFrFWjwGxXXk32PGeYTDHVnL+vJb1bHrKfRqNpBJXR1O6cDiGmz8Z7geMmq4/Qua6iRgn9oh7r3wiJZy2wg2Xj0eoPr1u9MusNgRL8fwutgzOclvl/Vo2mEVTWPtxNT5bhfv5J7++WJuryJA7raf/TaJJGo2kEHesy5s6hVy9LUrZl+OuCMfYJJ7tC4P1qhwDQEmk0jaDihZX/nfeyqy7XwLbS/gifQPgDiAV3/zcUfwte7Q8pVg6k0WgaQYWVp72iYLQw3TY5fB1wtAVQrJpwDXlW6fsB9H9xCc3kbvX/Ad/Ue7ktywTMv6bCBKdNSb6TqwvAu3lxA8Bx6RPii9FdJEAaQSX+jdXjBIdlkK0h8dugCX/3Kt9zog/wEWYcwsPOexqNphH0kuF7m+VsTTb9CCXO27D/ELGxE8uKL5sruvo0Gk0j6MXhu6FpDR59rKyyr5cmaMHAb3aDyzKNbEb9tBohAdIIKustGe5jJdTy7Vnd/QC+v6usKribm39cJE8SusPv6Ojo6Ojo6HgRfwGTJvF8ML1S8wAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIFSURBVGje7VrRbsMgDDySttv//+2aNOwBTrkxr6HSGpDFSVUSYnDNCWPjBFQgAIj5inxvyfDdBGCTq2KqUfif8K8wHAmQhwuAtegY5UrMWT4+Ge9U+Fd4yOEM4CHCUdqm3PYAcAWwFH2tNv9T2h+HxAWJP/L5AeAr398A3LGvVVqxGeP4n9L+OJyRuONvzp3Ur+q+pz537IenoHodWh35K30trSDvTS30r/CQQ/ISkdbUVf7pKjIBtu9sbqF/hZcjAfrPO4BPJJ5Wo+MmbfHJeP6ntD8OgcQZfSQXrpUragxb5iLNLPSvsMqXMl8nX8qV9dyVhf4VHnIYRZAxqu57VuypOcaIS9+OKg4XpFhGY049jwnYeYsH4/mf0v44pNCMxNGCxNeClNvrWYyeu4VsTelj/U9pvxySG3KmXClft+J9cwv9K6zikLyV59uxGETzxFK2mYX+FVbn+CrIZ/LFHJLxixXLNLPQv8KXfalVW2KsOhf9rJzD/5T2x6Hm8uTEqh3qfrli+NITUb0OWVviOmS9Sf0meWXbqB+eguq6RUDiY8J+5sb9kD5U34/98DRUfYsB7LHmZnTkOr3hp/8c5zSnoHodKh/M84kNqa6vdX4OPuqHb8dL+SGw+03lSmsUPHdb/hjL/5T2x2H5TRTwO7fns3Kp39s0tdC/woGBgYGBgQHgG71FhrA1+dOFAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAFSSURBVGje7ZjBcoQgEEQfuib//625bXZ1DzrFLDEFHqJkqt9FLdRh6GoYACGEEEIIIYQQAlLthWXnpRvwAAZgPhhwODvD+AGbNfwA7sWHy3/IMH7Aqoaz61Wp2wg8e88wfsBb7YVE1mrYrgmYgC/gs/cM4wes+vDJKrT5z6+BS8sPrs4wfsCm9dDm0+R6eN/uj/Y4/pD2pyGsPvwm6zke/cGVGcYPWJXA1zG+hkmsekrDywNWaxpfh5oHZ7InTWNbJ4fteWF//xF/SPvzoWlT7iPMh77Xi2sz/aThn9M0FZp+VtOYD+F9/2g1zqOnDOMHrM6lkH2VyFr6edJrN7v2vXO4+EPan4YjP33l9Zl496Vv13p4Cs1l5cS6v7APSs1MN5t37Vz88gzjB2zaW9gZ21hcfa+tDv3Nf5dlGD9gsw9Nl3IdtPu9szjNpUIIIYQ4iRdQSEp2rB0YggAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAFSSURBVGje7ZjBcoQgEEQfuib//625bXZ1DzrFLDEFHqJkqt9FLdRh6GoYACGEEEIIIYQQAlLthWXnpRvwAAZgPhhwODvD+AGbNfwA7sWHy3/IMH7Aqoaz61Wp2wg8e88wfsBb7YVE1mrYrgmYgC/gs/cM4wes+vDJKrT5z6+BS8sPrs4wfsCm9dDm0+R6eN/uj/Y4/pD2pyGsPvwm6zke/cGVGcYPWJXA1zG+hkmsekrDywNWaxpfh5oHZ7InTWNbJ4fteWF//xF/SPvzoWlT7iPMh77Xi2sz/aThn9M0FZp+VtOYD+F9/2g1zqOnDOMHrM6lkH2VyFr6edJrN7v2vXO4+EPan4YjP33l9Zl496Vv13p4Cs1l5cS6v7APSs1MN5t37Vz88gzjB2zaW9gZ21hcfa+tDv3Nf5dlGD9gsw9Nl3IdtPu9szjNpUIIIYQ4iRdQSEp2rB0YggAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAFeSURBVGje7ZnhbsMgDISPNev7P+9WYD/ghIXooKoWMus+KSqqLIw52TEEEEIIIYQQQgghgDAzyAuTRAA3Yx8B3OvkqbP9ODtC/w6PmcFUZBT9ohk/MNZvS4T+HU4lmhnkuupcnweKjqE+fR7739Lr5eFKLbU5R/1uaLpujdC/w5VSubTqjKIjx5eJ0L/DaR7OsDkYzf8HSl3dHqF/h29rSBJKL8oc5Hsxdnb+t/R/1lKgaBdqBOkXO/9bej0NaZDR6iNXmdBqaRjYXyJC/w5fzkN7jiDMwWDGGaqlJzF9H1rNbJ/CuvllJmIN5ZkxPpnvVPw7XMrD/h4moGmZB5OMzvbbIvTvcOl92OuUzW9C0fWOkpMHmt4jHf1v6fVqaR6MPwF8o+jHCagbex72Obqn+XOWexoaWn3s/VrsxqN+ZkuE/h0ufbewfWhE08/qSVh3n+nof0tPdyiEEEII4AfOzE9ypOy7UAAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAFNSURBVGje7ZnLboMwEEUPkPb/v7WrSCF2F3jUAUHsLBpbo3s2kMTM9XA1fgWEEEIIIYQQQgiYWhotwLPc34D18L0FycAMpBex5k9nGF+w6qF5Yt5ZD1f2ni0lWC73ubRLJ/E+SnzBZg8n4Bv4KdfM5qv3yNer+dk9w/iCTWOpJ5300mp0YvNxffF8/Fc6poczW02Zf2c++XnQ6vELePTOML5g1UM/PuaTB/wcmFy7q7VN/Fc6noce89B6mVyQq7lPa5p/51ZrYP54j+yz31NMh999/XbNML5gcx2mQ+OJ6/obKsP4gtU69HsL83Dlb88oD7sLNtehnwsX4M5+bhw2w/iCzWdt60nj3BqgZ4bxBatjqT8T9Z75c9OhM4wv+PbeAjb/bO+usbS7YLUOfa/svObBfo0zdIbxBd+ywcZVu9b+Zxoiw/iCQgghhIBfSzVBerEBoUkAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAJ5SURBVGje7ZnrjpswEIU/ICTb9v1ftd1kA/SH5+xMvKixtgIiyyOhBGIztk/OXDu+IR0wAPdwfwI+7H6wzxlYsrn9dxT+j9SvsCsZdCbh04VL+A3AZM96EmYzMNrvH9m76j/S18MwcuoCXEk4jSTsZhzHuIP5VXZYv8IiDKdwfwZuttLZXjDas9Gu3yTbel95X/1HurvCU8mKIobycYtNXux3cVT8m3CcD91h/QqL/OEP4A+Ja6ewyhvwC/d54l5Hwjbn8CE7rF/hUwyFy2KDLyTslvBMLxrsM8anDcPNpYiHwmok4SNc5Q9jTCrbq7GH77B+hU/9Yb4qgX7BcQPPF6dsbMsPN5ciHkYscvs42TPhGfPFtfyi/iN9PR4q3pS9FGbRfuqPoBhVvvIldli/wmIewiMu8nfCVHmjOCvsD99h/QqLMJR9HO37uz2PsWrEay0vPGyH9St8iqH4JYn+8Aq84fFoj9dm3mxey/E3lyIeShR7Xknc0+RYO5W0Wttu8hRD5fTqLUWfOOF1mxy/ifW4pv4jPQbDnsQl+TRhEmNScL5dSHXtOaxYceqA297cDh+yw/oVfmIYebR29oo31e9VXVRxKXgfSv6x2dJd5AR+9uLeja84qmeo2qmuOcxXXr/8Q2H9R7o/D2Ufde7CRnEmPNrHuFLlh2ceuRy52mptm8unLZXtU+yi2DOvlUae3Uk5hHIN5R2xP9ww3Fy6vOcH3tt9t+/CU7icbZzsaG/j9A7Z1lan2UU6SOcte6k+YOzX/8R7huA45b1e8W+tb3jYDutX2PV4fBljllhfUx9QGIm7ikdzWwreV2x1miZNmjRp0qTJDvIXmKW3rPqLJ84AAAAASUVORK5C\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "7-element Array{Array{RGB{Normed{UInt8,8}},2},1}:\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]\n",
       " [RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); … ; RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Images\n",
    "files = readdir(\"data/\")\n",
    "my_images = [load(\"data/\"*file) for file in files if(occursin(\".jpg\",file))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference all images in the array and time each inferecing using @time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "  0.000564 seconds (274 allocations: 33.016 KiB)\n",
      "6\n",
      "  0.000079 seconds (153 allocations: 16.688 KiB)\n",
      "4\n",
      "  0.000090 seconds (153 allocations: 16.688 KiB)\n",
      "4\n",
      "  0.000090 seconds (154 allocations: 17.078 KiB)\n",
      "7\n",
      "  0.000070 seconds (153 allocations: 16.688 KiB)\n",
      "6\n",
      "  0.000066 seconds (154 allocations: 17.219 KiB)\n",
      "3\n",
      "  0.000073 seconds (154 allocations: 17.078 KiB)\n"
     ]
    }
   ],
   "source": [
    "for i in 1:length(my_images)\n",
    "@time println(read_image(my_images[i]))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
